{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Shape: (100, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('data/raw/revenue_prediction.csv')\n",
    "    print(\"Data loaded successfully. Shape:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Check file path.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "Id              0\n",
      "Name            0\n",
      "Franchise       0\n",
      "Category        0\n",
      "City            0\n",
      "No_Of_Item      0\n",
      "Order_Placed    0\n",
      "Revenue         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill or drop missing values\n",
    "df = df.dropna()  # or df.fillna(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows:\n",
      "    Id                  Name Franchise       Category       City  No_Of_Item  \\\n",
      "0  101    HungryHowie'sPizza       Yes        Mexican  Bengaluru          55   \n",
      "1  102  CharleysPhillySteaks        No    Varied Menu   Gurugram          72   \n",
      "2  103                Chuy's       Yes        Chicken       Pune          25   \n",
      "3  104           O'Charley's       Yes  Italian/Pizza     Mumbai          18   \n",
      "4  105         PolloTropical       Yes          Pizza      Noida          48   \n",
      "\n",
      "   Order_Placed  Revenue  \n",
      "0           5.5  5953753  \n",
      "1           6.8  7223131  \n",
      "2           1.9  2555379  \n",
      "3           2.5  2175511  \n",
      "4           4.2  4816715  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "df['No_Of_Item'] = df['No_Of_Item'].replace(0, 1)  # Prevent division by zero\n",
    "df['Order_Item_Ratio'] = df['Order_Placed'] / df['No_Of_Item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical features\n",
    "df['Franchise'] = df['Franchise'].astype('category').cat.codes\n",
    "df['Category'] = df['Category'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "q_low = df['Revenue'].quantile(0.05)\n",
    "q_high = df['Revenue'].quantile(0.95)\n",
    "df = df[(df['Revenue'] > q_low) & (df['Revenue'] < q_high)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "features = ['Franchise', 'Category', 'No_Of_Item', 'Order_Placed', 'Order_Item_Ratio']\n",
    "X = df[features]\n",
    "y = df['Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/feature_scaler.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature scaling\n",
    "feature_scaler = StandardScaler()\n",
    "X_train_scaled = feature_scaler.fit_transform(X_train)\n",
    "X_test_scaled = feature_scaler.transform(X_test)\n",
    "joblib.dump(feature_scaler, 'models/feature_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/target_scaler.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target scaling\n",
    "target_scaler = StandardScaler()\n",
    "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "joblib.dump(target_scaler, 'models/target_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build neural network\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 540ms/step - loss: 4.4036 - mae: 1.2291 - val_loss: 1.2058 - val_mae: 0.5245\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 3.1042 - mae: 1.0865 - val_loss: 1.1977 - val_mae: 0.5267\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 3.0512 - mae: 1.0224 - val_loss: 1.2003 - val_mae: 0.5341\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 2.1728 - mae: 0.8201 - val_loss: 1.2095 - val_mae: 0.5441\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 2.2692 - mae: 0.8320 - val_loss: 1.2258 - val_mae: 0.5567\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.9899 - mae: 0.7163 - val_loss: 1.2443 - val_mae: 0.5690\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.7265 - mae: 0.7054 - val_loss: 1.2639 - val_mae: 0.5811\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.4257 - mae: 0.5558 - val_loss: 1.2880 - val_mae: 0.5947\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.6520 - mae: 0.6817 - val_loss: 1.3144 - val_mae: 0.6083\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4174 - mae: 0.5668 - val_loss: 1.3404 - val_mae: 0.6215\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3385 - mae: 0.5470 - val_loss: 1.3564 - val_mae: 0.6289\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 1.3552 - mae: 0.5297 - val_loss: 1.3677 - val_mae: 0.6353\n"
     ]
    }
   ],
   "source": [
    "# Train with early stopping\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('models/neural_network_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
